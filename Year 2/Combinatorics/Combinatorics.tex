\documentclass[a4paper, 12pt, twoside]{article}
\usepackage[left = 3cm, right = 3cm]{geometry}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{multicol}

\begin{document}

\title{Combinatorics Notes}
\date{}
\author{\textit{paraphrased by} Tyler Wright}
\maketitle

\vfill

\textit{An important note, these notes are absolutely \textbf{NOT}
  guaranteed to be correct, representative of the course, or rigorous.
  Any result of this is not the author's fault.}

\newpage

\section{Counting Techniques}

\subsection{The Bijection Rule}

For $n$ in $\mathbb{N}$, we define $[n] := \{1, 2, \ldots, n\}$.
\\[\baselineskip]
For a given set $X$, if there exists a bijective function 
$f : [n] \to X$ for some $n$ in $\mathbb{N}$, $X$ has $n$ elements
(or rather $|X| = n$).
\\[\baselineskip]
This can also be achieved by listing out the elements of 
$X = \{x_1, x_2, \ldots, x_n\}$ as we can use $f : [n] \to X$
where $i$ maps to $x_i$.

\subsection{The Addition Rule}

We can count the amount of elements in a given set $X$ by
splitting $X$ into disjoint sets, counting them, and adding the
results.
\\[\baselineskip]
For $n$ in $\mathbb{N}$, and $X_1, \ldots, X_n$ pairwise disjoint
sets: \begin{gather*}
  \left|\bigcup_{i = 1}^n X_i\right| = \sum_{i = 1}^n |X_i|.
\end{gather*} \textit{For a set of sets $A$, pairwise disjoint means 
for two given sets in $A$, they are either disjoint or equal.}

\subsection{The Multiplication Rule}

If a counting problem can be split into a number of stages, we can
use the product of the number of choices at each stage to find
the total number of outcomes.
\\[\baselineskip]
\textit{For example, if we want to find how many three digit numbers 
there are, we can consider it as choosing three digits. We can choose
$1, 2, \ldots, 9$ for the first digit and $0, 1, \ldots, 9$ for 
the rest so we get $9 \cdot 10^2$ possibilities.}

\subsection{Inclusion-Exclusion Principle}

For $n$ in $\mathbb{N}$, and $X_1, \ldots, X_n$ sets: \begin{align*}
  \left|\bigcup_{i = 1}^n X_i\right| &= \sum_{i = 1}^n |X_i| \\
  &-\sum_{i_1 \neq i_2} |X_{i_1} \cap X_{i_2}| \\
  &+\sum_{i_1 \neq i_2 \neq i_3} |X_{i_1} \cap X_{i_2} \cap X{i_3}| \\
  &\ldots
\end{align*} \textit{Essentially, this says that the size of the
union of some finite number of sets is the sum of their sizes,
minus the sum of their \textbf{paired} intersections,
plus the sum of the intersections of \textbf{trios}, etc.}

\subsection{The Factorial}

For $n$ in $\mathbb{N}$ we can define the factorial $n!$: \begin{align*}
  n! := \begin{cases*}
    1 & n = 0 \\
    \prod_{i = 1}^n(i) & \text{otherwise.}
  \end{cases*}
\end{align*} For $k$ in $\mathbb{N}$ we can further define $(n)_k$: \begin{gather*}
  (n)_k := \frac{n!}{(n-k)!} = n(n-1)(n-2)\cdots(n-k+1).
\end{gather*} \textit{This can be though of as the factorial with $k$
elements (starting at $n$). So, $(n)_n = n!$, $(n)_1 = n$, etc.}

\subsection{The Binomial Coefficient}

For $n, k$ in $\mathbb{N}$, we can define the binomial coefficient:  \begin{align*}
 {n \choose k} := \frac{n!}{k!(n-k)!} = \frac{(n)_k}{k!}.
\end{align*}
This is the number of ways of choosing $k$-element subsets
from an $n$-element set. 

\newpage

Furthermore, we have: \begin{gather*}
  {n \choose k} = {n \choose n - k},
\end{gather*} as choosing $k$ elements is equivalent to choosing
$n - k$ elements to remove.
\\[\baselineskip]
There are some notes to be made on the definition: \begin{itemize}
  \item ${n \choose k} = 0$ if $k > n$
  \item ${n \choose 0} = {n \choose n} = 1$
  \item ${n \choose k} \geq 0$
\end{itemize}

\subsection{Pascal's Identity}

Say we are selecting $k$ elements from an $n$-element set (unordered, 
without repeats). We will see that there are ${n \choose k}$ possibilities.
If we fix an element in the set, we can either include said element in
our selection or exclude it giving ${n - 1 \choose k - 1}$ and 
${n - 1 \choose k}$ possibilities respectively. Thus: \begin{gather*}
  {n \choose k} = {n - 1 \choose k - 1} + {n - 1 \choose k}.
\end{gather*}

\subsection{The Binomial Theorem}

By performing induction on Pascal's identity, we can see that for 
$a, b$ in $\mathbb{C}$ and $n$ in $\mathbb{N}$: \begin{gather*}
  (a + b)^n = \sum_{i = 0}^n {n \choose i}a^ib^{n - i}.
\end{gather*} Setting $a = b = 1$, we get $2^n = \sum_{i = 0}^n 
{n \choose i}$.

\subsection{The Pigeonhole Principle}

For $m, n, k$ in $\mathbb{N}$, if we have $k$ objects being 
distributed into $n$ boxes and $n > mk$ then one box must contain
at least $k + 1$ objects.

\newpage

\section{Selection}

For this section, we will consider $n, k$ in $\mathbb{N}$.

\subsection{Ordered Selection with Repeats}

As we select, we have $n$ choices, and we select $k$ times. Thus,
by the Multiplication Rule, we get $n^k$ outcomes.

\subsection{Ordered Selection without Repeats}

As we select, the amount of choices we have decreases by one each time.
We start with $n$ choices and select $k$ times. Thus, by the Multiplication
Rule, we get \newline $n(n-1)\cdots(n-k+1) = (n)_k$ outcomes.

\subsection{Unordered Selection with Repeats}

Let the set we are selecting from be $\{x_1, \ldots, x_n\}$. In this case, 
any solution can be aggregated into a list indicating how
many times the $i^{\text{th}}$ element was selected (for some $i$ in $[n]$).
For example, if we select $x_1$ three times and $x_2$ five times, 
the outcome would be of the form $\{3, 5, \ldots\}$.
\\[\baselineskip]
It can be seen that for each of these solutions, the sum of the elements in
the set must equal $k$. We can construct a solution by starting with a set
of all zeroes $\{0, 0, 0, \ldots\}$ and distributing $k$ into the set. For
example, for $n = 4$ and $k = 3$ the following are solutions: \begin{gather*}
  \{1, 1, 1, 0\} \text{ as } 1 + 1 + 1 + 0 = 3 = k, \\
  \{0, 2, 0, 1\} \text{ as } 0 + 2 + 0 + 1 = 3 = k, \\
  \{3, 0, 0, 0\} \text{ as } 3 + 0 + 0 + 0 = 3 = k.
\end{gather*} These solutions correspond to $\{x_1, x_2, x_3\}, 
\{x_2, x_2, x_4\}, \{x_1, x_1, x_1\}$ respectively.
\\[\baselineskip]
This distribution of $k$ can be thought of as seperating $k$ into $n$
groups. For example, the solution $\{1, 1, 0, 1\}$ corresponds to: \begin{gather*}
  \bullet | \bullet | | \bullet.
\end{gather*} 

\newpage

The dots and dividers are identical respectively, and we
have a total of $k$ dots plus $n - 1$ dividers equalling $k + n - 1$
elements. We can choose where to place the dividers beforehand and
then fill in the dots, thus we have: \begin{gather*}
  {k + n - 1 \choose n - 1}
\end{gather*} choices.

\subsection{Unordered Selection without Repeats}

This is identical to to the ordered case but we divide by the number
of permutations of the solutions as order does not matter. Thus, we get:
\begin{gather*}
  \frac{(n)_k}{k!} = {n \choose k}.
\end{gather*}

\vfill

\section{Generating Functions}

\subsection{Definition of a Generating Function}

For a sequence $(a_n)_{n \geq 0}$, we
can associate a \textbf{formal power series}: \begin{gather*}
  f(x) = \sum_{k = 0}^\infty a_nx^n = a_0 + a_1x + a_2x^2 + \cdots.
\end{gather*} We say $f(x)$ is the generating function of $(a_n)$,
or write: \begin{align*}
  a_0, a_1, a_2, \ldots &\leftrightarrows a_0 + a_1x + a_2x^2 + \cdots \\
  (a_n)_{n \geq 0} &\leftrightarrows f(x).
\end{align*} Note, however, that this doesn't imply that the series is convergent.

\subsection{Generating Functions of Finite Sequences}

For finite sequences (or rather, sequences with finitely many
non-zero terms), we have that their generating functions
can be written as polynomials.

\subsection{The Scaling Rule}

For a sequence $(a_n)_{n \geq 0}$ with an
associated generating function $f(x)$ and $c$ in $\mathbb{R}$: \begin{gather*}
  (ca_n)_{n \geq 0} \leftrightarrows cf(x).
\end{gather*}

\subsection{The Addition Rule}

For the sequences $(a_n)_{n \geq 0}$, $(b_m)_{m \geq 0}$ 
with the associated generating functions $f(x), g(x)$ respectively: \begin{gather*}
  (a + b)_{n \geq 0} \leftrightarrows f(x) + g(x).
\end{gather*}

\subsection{The Right-Shift Rule}

For a sequence $(a_n)_{n \geq 0}$ with an associated generating 
function $f(x)$, we can add $k$ in $\mathbb{N}$ leading zeroes by
multiplying the sequence by $x_k$: \begin{gather*}
  0, \ldots, 0, a_0, a_1, \ldots \leftrightarrows x^kf(x).
\end{gather*}

\subsection{The Differentiation Rule}

For a sequence $(a_n)_{n \geq 0}$ with an associated generating 
function $f(x)$, we have that: \begin{gather*}
  a_1, 2a_2, 3a_3, \ldots \leftrightarrows \frac{d}{dx}f(x).
\end{gather*} \textit{So, each element in the sequence
is multiplied by its index and left-shifted by one, with
the farthest left term (the constant) removed.}

\subsection{The Convolution Rule}

For the sequences $(a_n)_{n \geq 0}, (b_m)_{m \geq 0}$ with 
associated generating functions $f(x), g(x)$ respectively.
We have that: \begin{gather*}
  c_0, c_1, c_2, \ldots \leftrightarrows f(x) \cdot g(x),
\end{gather*} where: \begin{gather*}
  c_n := \sum_{i = 0}^{n} a_ib_{n - i} = a_0b_n + a_1b_{n-1} 
  + \cdots + a_{n-1}b_1 + a_nb_0.
\end{gather*}

\subsection{The Negative Binomial Theorem}

For all $n$ in $\mathbb{N}$, we have that: \begin{gather*}
  (1 + x)^{-n} = \sum_{k = 0}^\infty (-1)^k{n + k - 1 \choose n - 1}x^k.
\end{gather*}

\vfill

\section{Combinatorial Designs}

\subsection{Definition of a Set System}

For $V$ a finite set, we let $B$ be a collection of subsets of $V$.
We call the pair $(V, B)$ a set system with \textbf{ground set} $V$.
\\[\baselineskip]
If for all elements in $B$, each element has the same cardinality $k$,
we have that $(V, B)$ is \textbf{$k$-uniform}.  
\\[\baselineskip]
\textit{We have that $B \subseteq \mathcal{P}(V)$ (that is, the 
powerset of $V$).}
 
\subsection{Definition of Block Design} For $v, k, t, \lambda$ integers,
we suppose: \begin{gather*}
  v > k \geq t \geq 1, \qquad \lambda \geq 1.
\end{gather*} A block design of type: \begin{gather*}
  t-(v, k, \lambda),
\end{gather*} is a set system $(V, B)$ with the following properties:
\begin{itemize}
  \item $V$ has size $v$
  \item $(V, B)$ is $k$-uniform
  \item Each $t$-element subset of $V$ is contained in exactly
  $\lambda$ 'blocks' (elements of $B$).
\end{itemize}

\subsection{The Quantity of Blocks in a Block Design}

For a block design of type $t-(v,k,\lambda)$, we have that the number
of blocks $b$ can be derived as follows: \begin{gather*}
  b = \frac{\lambda{v \choose t}}{{k \choose t}}.
\end{gather*}

\subsection{Definition of the Replication Number}

In a block design of type $2-(v,k,\lambda)$, every element lies in
exactly $r$ blocks where: \begin{gather*}
  r(k - 1) = \lambda(v - 1), \qquad bk = vr.
\end{gather*} $r$ is the replication number.

\subsection{Fisher's Inequality}

For $(V, B)$ a block design of type $2 - (v, k, \lambda)$ with $v > k$,
we have that: \begin{gather*}
  |B| \geq |V|.
\end{gather*}

\subsection{Definition of an Incidence Matrix}

For a set system $(V, B)$ with $|V| = v$ and $|B| = b$ we define the
incidence matrix $A$ as a matrix in $M_{v, b}$ where $A = (a_{ij})$ 
and: \begin{gather*}
  a_{ij} = \begin{cases}
    1 & \text{if element } i \text{ is in block } j \\
    0 & \text{otherwise}.
  \end{cases}
\end{gather*} There are some important notes to be made: \begin{itemize}
  \item Each column contains $k$ many '$1$'s
  \item Each row contains $r$ (the replication number) many '$1$'s
  \item Each pair of rows contains $\lambda$ many '$1$'s in the same
  column
\end{itemize}

\vfill

\section{The Basics of Graph Theory}

\subsection{Definition of a Graph}

A graph $G$ is a set system $(V, E)$ where the elements of $E$ have
size $2$. Some definitions and facts follow from the definition:
\begin{itemize}
  \item The elements of $V$ are \textbf{vertices}
  \item The elements of $E$ are called \textbf{edges}
  \item The size of $V$ is often called the \textbf{order} of $G$
  \item $G$ is a $2$-uniform set with ground set $V$
  \item $u, v$ in $V$ are adjacent if ${u, v}$ is in $E$.
\end{itemize}  

\subsection{Graph Isomorphisms}

For two graphs $G_1 = (V_1, E_1)$, $G_2 = (V_2, E_2)$, we say that
$G_1$ and $G_2$ are isomorphic ($G_1 \cong G_2$) if there exists a
bijection $\phi : V_1 \to V_2$ such that for each pair of vertices
$u, v$ in $V$ we have that: \begin{gather*}
  \{u, v\} \in E_1 \Longleftrightarrow \{\phi(u), \phi(v)\} \in E_2.
\end{gather*}

\subsection{Definition of Neighbourhood and Degree}

For a graph $G = (V, E)$ the \textbf{neighbourhood} of $v$ in $V$ 
is the set of all adjacent vertices (denoted by $N_G(v)$). The
neighbourhood of a set $S$ is simply the union of the neighbourhoods
of the elements of $S$.
The \textbf{degree} is simply the size of $N_G(v)$ denoted 
by $\text{deg}(v)$.

\subsection{Notation for Minimum and Maximum Degree}

For a graph $G = (V, E)$ we have that the following to represent
minimum and maximum degree: \begin{align*}
  \delta(G) &:= \text{min}\{\text{deg}(v) : v \in V\} \\
  \Delta(G) &:= \text{max}\{\text{deg}(v) : v \in V\}.
\end{align*}

\subsection{Definition of Degree Sequence}

For a graph $G = (V, E)$ a graph with $V = \{x_1, \ldots, x_n\}$,
where $V$ is ordered such that $i \geq j$ implies $\text{deg}(x_i)
\geq \text{deg}(x_j)$. The sequence $(d_k)_{k \in [n]}$ is defined
as follows: $d_i = \text{deg}(x_i).$

\subsection{The Handshake Lemma}

For a graph $G = (V, E)$, we have that: \begin{gather*}
  |E| = \frac{\sum_{v \in V} \text{deg}(v)}{2}.
\end{gather*} \textit{This is because each edge visits two vertices,
so by counting the degree of each vertex we count each edge exactly
twice.}

\subsection{Subgraphs}

\subsubsection{Definition of a subgraph}

A graph $G' = (V', E')$ is a subgraph of $G = (V, E)$ if
$V' \subseteq V$ and $E' \subseteq E$ such that for all $e$
in $E'$ we have that $e \subseteq V'$.

\subsubsection{Definition of an induced subgraph}

An induced subgraph generated of $G = (V, E)$
is a subgraph $G' = (V', E')$ where: \begin{gather*} 
  E' = \{\{u, v\} \in E \text{ such that } u, v \in V'\}.
\end{gather*} \textit{Essentially, you generate an induced
subgraph from a subset of the vertices of a graph by selecting
edges that join vertices in the subset.}

\subsection{Walks}

\subsubsection{Definition of a walk}

We have that a walk of length $n$, is a set of
$n + 1$ vertices connected by $n$ edges.

\subsubsection{Definition of a trail}

A trail is a walk where no edges are repeated.

\subsubsection{Definition of a path}

A path is a walk where no vertices are repeated (barring the 
last one).

\subsubsection{Definition of a circuit}

A circuit is a walk where the first and last vertices are identical.

\subsubsection{Definition of a cycle}

A cycle is a path where the first and last vertices are identical.

\subsubsection{Equivalence of walks and paths}

If for some graph $G = (V, E)$ with $u, v$ in $V$, we have that:
\begin{gather*}
  \text{There's a walk between } u \text{ and } v
  \Longleftrightarrow
  \text{There's a path between } u \text{ and } v.
\end{gather*} Thus, where there's a cycle, there's a circuit.
\\[\baselineskip]
If we have that a graph $G$ has an odd circuit, there's also
an odd cycle (and the converse holds too).

\subsubsection{Definition of connected graph}

A graph is connected if there exists a path (or walk) 
between any two vertices in the graph.

\subsection{Definition of a Component}

A component of a graph $G$ is a maximal connected 
induced subgraph of $G$. This means an induced subgraph of $G$
that is connected but is not longer connected if a vertex is
removed.

\section{Euler Circuits}

\subsection{Definition of an Euler Circuit}

An Euler circuit is a circuit in which each edge in a graph is
traversed exactly once (or a trail which traverses every edge).
As a consequence, each vertex is travelled at least once.
\\[\baselineskip]
Graphs with Euler circuits are said to be \textbf{Eulerian}.

\subsection{Conditions for an Euler Circuit}

An Euler circuit in a graph $G$ exists if and only if $G$ is 
connected and each vertex in $G$ has even degree.

\section{Hamiltonian Cycles}

\subsection{Definition of a Hamiltonian Cycle}

For a graph $G = (V, E)$ where $|V| = n$, a Hamiltonian cycle in $G$ is
a cycle of length $n$, meaning it visits each vertex exactly once.
\\[\baselineskip]
Graphs with Hamiltonian cycles are said to be \textbf{Hamiltonian}.

\subsection{Definition of a Hamiltonian Path}

For a graph $G = (V, E)$ where $|V| = n$, a Hamiltonian path is a path of
length $n - 1$, meaning it visits each vertex at least once.

\subsection{Dirac's Theorem}

For a graph $G = (V, E)$ where $|V| \geq 3$: \begin{gather*}
  \delta(G) \geq \frac{n}{2} \Rightarrow G \text{ is Hamiltonian.}
\end{gather*}

\vfill

\section{Bipartite Graphs}

\subsection{Definition of a Bipartite Graph}

A graph $G = (V, E)$ is bipartite if $V$ can be partitioned into
two vertex sets $V_1, V_2$ such that each edge connects a vertex
from $V_1$ to a vertex in $V_2$.

\subsection{Characterisation of Bipartite Graphs}

A graph is bipartite if and only if it contains no odd cycle.

\subsection{The Handshake Lemma for Bipartite Graphs}

We have that for $G = (V, E)$ a bipartite graph with bipartition
$V_1, V_2$: \begin{gather*}
  \sum_{v \in V_1} \text{deg}(v) = \sum_{v \in V_2} \text{deg}(v). \\
\end{gather*}

\subsection{Hall's Marriage Problem}

\subsubsection{Definition of a Matching}

For $G = (V, E)$ a bipartite graph with bipartition $X, Y$,
a matching from $X$ to $Y$ is a set of edges: \begin{gather*}
  M = \{(x, y) : x \in X, y \in Y\},
\end{gather*} such that $f : X \to Y$ defined by: \begin{gather*}
  f(x) := y \qquad \text{ where } (x, y) \in M,
\end{gather*} is injective.
\\[\baselineskip]
\textit{In other words, $|M| = |X|$ and each $y$ in $Y$ appears 
in at most one edge in $M$.}

\subsubsection{Hall's Marriage Theorem}

For $G = (V, E)$ a bipartite graph with bipartition $X, Y$: \begin{gather*}
  G \text{ has a matching from } X \text{ to } Y \\
  \Longleftrightarrow \\
  \text{For all } S \subseteq X, |N(S)| \geq |S|.
\end{gather*} We also have that if: \begin{gather*}
  \text{min}_{x \in X}\big[\text{deg}(x)\big] \geq
  \text{max}_{y \in Y}\big[\text{deg}(y)\big],
\end{gather*} then $G$ has a matching from $X$ to $Y$.

\vfill

\section{Trees and Forests}

\subsection{Definition of a Forest}

A graph $F = (V, E)$ is a forest if it has no cycles
(is \textbf{acyclic}).

\subsection{Definition of a Tree}

A graph is a tree if it is a forest and is connected.

\subsection{Definition of a Leaf}

For a vertex $v$ in a tree, $v$ is a leaf if it has degree one.

\subsection{Existence of Leaves}

For a tree $T$ of order $2$ or more, we have that $T$ has a leaf.

\subsection{Characterisation of Trees}

We have that for a graph $G = (V, E)$, the following is equivalent:
\begin{itemize}
  \item $G$ is a tree
  \item $G$ is maximally acyclic ($G$ is acyclic and the addition
  of any edge forms a cycle)
  \item $G$ is minimally connected ($G$ is connected and the removal
  of any edge disconnects it)
  \item $G$ is connected and $|E| = |V| - 1$
  \item $G$ is acyclic and $|E| = |V| - 1$
  \item Any two vertices in $G$ are connected by a unique path.
\end{itemize}

\subsection{Minimum Spanning Trees}

In a connected, undirected graph $G = (V, E)$, we have that a
spanning tree $T = (V, E')$ of $G$ is a subgraph of $G$ where
$T$ is a tree and $E' \subseteq E$.
\\[\baselineskip]
A spanning tree on $G$ is minimal if there is no other spanning tree
on $G$ with a lower weight.

\subsubsection{Existence of spanning trees}

We have that there is a spanning tree in a graph $G$ if and only if
$G$ is connected.

\newpage

\subsubsection{Kruskal's algorithm}

For a graph $G = (V, E)$, we have 
the following steps to the algorithm: \begin{enumerate}
  \item Generate a graph $T = (V, \emptyset)$
  \item Sort the edges by weight
  \item For each edge $(u, v)$ (in increasing order): \begin{itemize}
    \item If $u$ or $v$ are not connected in $T$, add $(u, v)$ to $T$
    \item Stop if there are $|V| - 1$ edges in $T$ or if we have run
    out of edges.
  \end{itemize}
\end{enumerate} When this terminates, if the order of $T$ is $|V| - 1$
then $T$ is a minimum spanning tree. Otherwise, $T$ is an acyclic
graph with $n - k$ components.

\section{Cliques and Independent Sets}

\subsection{Definition of a Triangle}

We often call $K_3$ (the complete graph on three vertices) a triangle. A graph $G$
contains a triangle if a subgraph of $G$ is isomorphic to $K_3$.

\subsection{Mantel's Theorem}

For $G = (V, E)$ a graph of order $n$ that contains no triangles, we have that: \begin{gather*}
  |E| \leq \left\lfloor \frac{n^2}{4} \right\rfloor = \left\lfloor \left(\frac{n}{2}\right)^2 \right\rfloor.
\end{gather*} We also have that: \begin{gather*}
  \left[ |E| = \left\lfloor \frac{n^2}{4} \right\rfloor \right]
  \Rightarrow
  \left[ G \cong K_{k, n - k} \text{ where } k = \left\lfloor \frac{n}{2} \right\rfloor \right],
\end{gather*} there always exists a graph where the equality above holds.

\section{Planar Graphs}

The motivator for understanding planar graphs is the problem of drawing graphs in
the plane without intersecting edges.

\subsection{Definition of an Arc}

An arc is a subset of $\mathbb{R}^2$ of the type $\sigma : [0, 1] \to \mathbb{R}^2$ 
where $\sigma$ is an injective, continuous map and $\sigma(0), \sigma(1)$
are the endpoints of the arc. Injectivity here ensures the arc does not cross itself.

\subsection{Definition of a Drawing}

For a graph $G = (V, E)$, drawing it is equivalent to assigning: \begin{itemize}
  \item A point $p$ in $\mathbb{R}^2$ for each $v$ in $V$ (such that the map
  from vertices to points is injective)
  \item An arc $\sigma$ for each $e = (x, y)$ in $E$ (such that $\sigma$ intersects
  exactly two points, the points corresponding to $x$ and $y$).
\end{itemize}

\subsection{Definition of a Planar Drawings and Graphs}

A drawing with a set of arcs $A$ is planar if for each $\sigma_1, \sigma_2$ in $A$, 
we have that $\sigma_1, \sigma_2$ either intersect at their endpoints or not at all.
\\[\baselineskip]
A graph is planar if it admits at least one planar drawing. We have that $K_5$ 
and $K_{3, 3}$ are not planar.

\subsubsection{Non-Planar Subgraphs}

For a graph $G$ with $G'$ a subgraph of $G$ that is not planar, we have that
$G$ is not planar.

\subsection{Definition of a Jordan Curve}

An arc in the plane whose endpoints conincide is called a Jordan curve.

\subsection{Jordan Curve Theorem}

For any Jordan curve $C$, $C$ divides the plane into exactly two connected regions
called the 'interior' and 'exterior'. The curve is the boundary of these regions. 

\subsection{Definition of a Face}

For a planar graph $G$, a face of a drawing of $G$ is a connected region
bound by the drawing. The region going off to infinity is the outer face and
the rest are inner faces.

\subsection{Euler's Formula}

For a connected graph $G = (V, E)$ where $F$ is the set of faces of a given 
drawing of $G$, we have that: \begin{gather*}
  |V| - |E| + |F| = 2.
\end{gather*}

\end{document}