\documentclass[a4paper, 12pt, twoside]{article}
\usepackage[left = 3cm, right = 3cm]{geometry}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.5.1}

\begin{document}

\title{Data Structures and Algorithms Notes}
\date{}
\author{\textit{paraphrased by} Tyler Wright}
\maketitle

\vfill

\textit{An important note, these notes are absolutely \textbf{NOT}
  guaranteed to be correct, representative of the course, or rigorous.
  Any result of this is not the author's fault.}

\newpage

\section{Graph Theory}

\subsection{Definition of a Graph}

A graph is a pair of sets $G = (V, E)$, where $V$ is a set of 
vertices (or nodes) and $E$ is a set of edges (or arcs).

\subsection{Definition of an Edge}

An edge of a graph $G = (V, E)$ is $e = \{u, v\}$ in $E$ where $u$,
$v$ are vertices in $V$.

\subsection{Definition of a Neighbourhood}

For a graph $G = (V, E)$ with $v$ in $V$, the neighbourhood
of $v$ is the set $V' \subseteq V$ of vertices connected to
$v$ by an edge in $E$.
\\[\baselineskip]
The neighbourhood of $v$ is denoted by $N(v)$.
\\[\baselineskip]
The neighbourhood of a set of vertices is the union of
the neighbourhoods of each vertex.

\subsection{Definition of Degree}

For a graph $G = (V, E)$ with $v$ in $V$, the degree of $v$
is the size of its neighbourhood.
\\[\baselineskip]
The degree of $v$ is denoted by $d(v)$.

\subsection{The Handshake Lemma}

For a graph $G = (V, E)$, we have that: \begin{gather*}
  |E| = \frac{\sum_{v \in V} d(v)}{2}.
\end{gather*} \textit{This is because each edge visits two vertices,
so by counting the degree of each vertex we count each edge exactly
twice.}

\newpage

\subsection{$k$-regular Graphs}

For a graph $G = (V, E)$, we have that $G$ is $k$-regular for some
$k$ in $\mathbb{Z}_{>0}$ if for all $v$ in $V$, we have: \begin{gather*}
  d(v) = k.
\end{gather*} We cannot have a $k$-regular graph where $k$ is odd
and $|V|$ is odd by the Handshake Lemma.

\subsection{Isomorphic Graphs}

Graphs $G_1 = (V_1, E_1)$ and $G_2 = (V_2, E_2)$ are called 
isomorphic if there exists a bijection $f : V_1 \to V_2$ such
that: \begin{gather*}
  \{u, v\} \in E_1 \Longleftrightarrow \{f(u), f(v)\} \in E_2.
\end{gather*} This relationship is denoted by $G_1 \cong G_2$.

\subsection{Definition of a Subgraph}

A graph $G' = (V', E')$ is a subgraph of $G = (V, E)$ if
$V' \subseteq V$ and $E' \subseteq E$.

\subsection{Definition of an Induced Subgraph}

An induced subgraph generated from $G = (V, E)$ by $V' \subseteq V$
is the graph $G' = (V', E')$ where: \begin{gather*} 
  E' = \{\{u, v\} \in E \text{ such that } u, v \in V'\}.
\end{gather*} \textit{Essentially, you generate an induced
subgraph from a subset of the vertices of a graph by selecting
edges that join vertices in the subset.}

\subsection{Walks}

\subsubsection{Definition of a walk}

A walk in a graph $G = (V, E)$ is a set of vertices in $V$ connected
by edges in $E$. The length of the walk is the number of edges
traversed in the walk.

\subsubsection{Definition of a path}

A path is a walk where no vertices are repeated.

\subsubsection{Definition of an Euler walk}

An Euler walk is a walk such that every edge is traversed exactly
once. Thus, for a graph $G = (V, E)$, the length is $|E|$.

\subsubsection{Conditions for an Euler walk}

For an Euler walk to be possible on a given graph,
all vertices must have an even degree \textbf{or} exactly
two vertices have odd degree. 
\\[\baselineskip]
If all vertices have even degree we 
have that the Euler walk is a cycle, if exactly two vertices have
odd degree then we have that these vertices are the start and end
points of our Euler walk. 

\subsection{Definition of a Connected Graph}

A connected graph is a graph where for each pair of vertices,
there is a path connecting them.

\subsection{Definition of a Component}

A component of a graph $G$ is a maximal connected 
induced subgraph of $G$. This means an induced subgraph of $G$
that is connected but is not longer connected if a vertex is
removed.

\subsection{Digraphs}

\subsubsection{Definition of a digraph}

A digraph (or directed graph) is a graph where each of the edges
has a direction. This direction means the edge can only be traversed
in a single direction.

\subsubsection{The Directed Handshake Lemma}

For a digraph $G = (V, E)$, we have that: \begin{gather*}
  \sum_{v \in V} d^-(v) = \sum_{v \in V} d^+(v) = |E|.
\end{gather*} \textit{This is because if we consider the 'tail' of an
edge (the vertex it leaves), each edge has exactly one tail.}

\subsubsection{Definition of a strongly connected digraph}

A digraph $G = (V, E)$ is strongly connected if for each $u, v$
in $E$, there exists a path from $u$ to $v$ \textbf{and} 
from $v$ to $u$.

\subsubsection{Definition of a weakly connected digraph}

A digraph $G = (V, E)$ is weakly connected if for each $u, v$
in $E$, there exists a path from $u$ to $v$ \textbf{or} 
from $v$ to $u$.

\subsubsection{Definition of components of digraphs}

A strong component of a digraph is the maximal \textit{strongly}
connected induced subgraph.
\\[\baselineskip]
A weak component of a digraph is the maximal \textit{weakly}
connected induced subgraph.
\\[\baselineskip]
\textit{So, these are induced subgraphs that are strongly/weakly
connected but are no longer strongly/weakly connected once a
vertex is removed.}

\subsubsection{Definition of neighbourhoods in digraphs}

The neighbourhood of a vertex in a digraph can be considered by
looking at the edges \textit{from} the vertex and the edges
\textit{to} the vertex.
\\[\baselineskip]
The in-neighbourhood of a vertex $v$ are the edges that enter $v$.
The out-neighbourhood of a vertex $v$ are the edges that exit $v$.
These are denoted by $N^-(v)$ and $N^+(v)$ respectively.

\subsubsection{Definition of degrees in digraphs}

For a vertex $v$, the in-degree of the vertex $d^-(v)$ is the size of
the in-neighbourhood and the out-degree of the vertex $d^+(v)$
is the size of the out-neighbourhood.
\\[\baselineskip]
It can be seen that the degree of a given vertex is the sum of
its in and out degree (in a digraph).

\newpage

\subsubsection{Conditions for an Euler walk in a digraph}

For an Euler walk to be possible on a given digraph, we have
two cases, either:\begin{itemize}
  \item the digraph is strongly connected and every vertex
  has equal in and out degrees, or
  \item one vertex has an in-degree one greater than its out-degree,
  another has an out-degree one greater than its in-degree, and all
  remaining vertices have equal in and out degrees.
\end{itemize}
In the first case we have that the Euler walk is a cycle, 
in the second we have that the special vertices are the start and end
points of our Euler walk. 

\subsubsection{Cycles}

\subsubsection{Definition of a cycle}

A cycle is a walk where the first and last vertices are the same
and each vertex appears at most once (barring the first and last
vertex).

\subsubsection{Definition of a Hamiltonian cycle}

A Hamiltonian cycle is a cycle where each vertex is visited.

\subsubsection{Conditions for a Hamiltonian cycle}

Whilst the conditions necessary for a Hamiltonian cycle in general
are unknown, by Dirac's theorem, we know that for a graph with
$n$ vertices, if every vertex has degree $\frac{n}{2}$ or greater
then a Hamiltonian cycle exists.

\subsection{Trees}

\subsubsection{Definition of a forest}

A forest is a graph with no cycles.

\subsubsection{Definition of a tree}

A tree is a connected forest (or a connected graph with no cycles).

\subsubsection{Path uniqueness of trees}

For a tree $T = (V, E)$, we have that for any $u, v$ in $V$, there
exists a unique path from $u$ to $v$.
\\[\baselineskip]
\textit{To prove this, suppose there are two unique paths between
$u$ and $v$. These paths must diverge and if we connect them, they
form a cycle which contradicts the definition of a tree.}

\subsubsection{The magnitude of edges in trees}

For a tree $T = (V, E)$, we have that $|E| = |V| - 1$.

\subsubsection{Rooted trees}

For a tree $T = (V, E)$, we can root $T$ with some $r$ in $V$.
For $v$ in $V\setminus{r}$, we define $P_v$ to be the path from 
$r$ to $v$, we then direct the edges from $r$ to $v$ for each $P_v$.
\\[\baselineskip]
For $u, v$ in $V\setminus\{r\}$, we say that: \begin{itemize}
  \item $u$ is an \textbf{ancestor} of $v$ if $u$ lies on $P_v$
  \item $u$ is the \textbf{parent} of $v$ if $u$ is in the
  in-neighbourhood of $v$
  \item $v$ is a \textbf{leaf} if it has degree $1$
  \item $L_0 = \{r\}$ and $L_n = \{v : |P_v| = n\}$ are the 
  \textbf{levels} of $T$
  \item The \textbf{depth} of a tree is the greatest $n$ where
  $L_n$ is non-empty.
\end{itemize} 

\subsubsection{Lower bound on the amount of leaves in a tree}

For a tree with $T = (V, E)$, if $V > 1$, there must be at least
$2$ leaves.

\subsubsection{Equivalent statements to the tree definition}

For a graph $T = (V, E)$, we have that the following are
equivalent: \begin{itemize}
  \item $T$ is a tree
  \item $T$ is connected and has no cycles
  \item $|E| = n - 1$ and T is connected
  \item $|E| = n - 1$ and T has no cycles
  \item T has a unique path between any two vertices
\end{itemize}

\subsection{Bipartitions}

\subsubsection{Definition of a bipartite graph}

For $G = (V, E)$, we have that $G$ is bipartite if there exists
$A \subset V$, $B \subset V$ such that $A$ and $B$ are disjoint
and the induced subgraphs of $A$ and $B$ have no edges. $A$
and $B$ are bipartitions of $G$.
\\[\baselineskip]
Saying $G$ is bipartite is equivalent to saying $G$ has no
cycles of odd length.
 
\subsubsection{Definition of a matching}

A matching in a graph is a set of disjoint edges.
\\[\baselineskip]
A matching is \textbf{perfect} if each vertex is contained in
some matching edge.

\subsubsection{Definition of a semi-matching}

For $k$ in $\mathbb{Z}_{>0}$, a $k$ to 1 semi-matching in a
bipartite graph $G$ with a bipartition $\{A, B\}$ is a subgraph
of $G$ where each vertex in $A$ has degree at most $k$ and
each vertex in $B$ has degree at most $1$.

\subsubsection{Definition of an augmenting path}

Given a matching $M$ in a bipartite graph $G = (V, E)$, 
an augmenting path is a set of vertices in $V$ connected
by edges $e_i$ in $E$ such that: \begin{align*}
  e_i \text{ is } \begin{cases}
    \text{in } M & \text{for } i \text{ odd} \\
    \text{not in } M & \text{for } i \text{ even}. \\
  \end{cases}
\end{align*} With the condition that the first and last vertices
in the path are not in the matching.

\subsubsection{Hall's Theorem}

For a bipartite graph $G = (V, E)$ with the bipartition $(A, B)$ has
a perfect matching if and only if $|A| = |B|$ and for all 
$X \subseteq A$, $|N(X)| \geq |X|$. 

\section{Types of Algorithms}

\subsection{Greedy Algorithms}

These types of algorithms start with a trivial solution and
iteratively optimise their solution based on the information
available at the time. They do not retroactively change the solution
based on new data, only add to it.

\section{Data Structures}

\subsection{Stacks}

A stack is a list of variables. It supports three operations:

\begin{center}
  \begin{tabular}{ || c | p{6.5cm} | c || }
    \hline
    Name & Description & Worst case runtime \\
    \hline
    \texttt{create()} & Creates a new stack & $O(1)$ \\
    \hline
    \texttt{push(x)} & Adds \texttt{x} to the end of the stack & $O(1)$ \\
    \hline
    \texttt{pop()} & Removes and returns the last element of the stack & $O(1)$ \\
    \hline
  \end{tabular}
\end{center}

\subsection{Queues}

A queue is a list of variables. It supports three operations:

\begin{center}
  \begin{tabular}{ || c | p{6.5cm} | c || }
    \hline
    Name & Description & Worst case runtime \\
    \hline
    \texttt{create()} & Creates a new queue & $O(1)$ \\
    \hline
    \texttt{add(x)} & Adds \texttt{x} to the end of the queue & $O(1)$ \\
    \hline
    \texttt{serve()} & Removes and returns the first element of the queue & $O(1)$ \\
    \hline
  \end{tabular}
\end{center}

\subsection{Linked List}

A linked list is a list of variables represented by nodes which
point to the next and previous element in the list (null if one does
not exist). 
It supports four operations:

\begin{center}
  \begin{tabular}{ || c | p{6.5cm} | c || }
    \hline
    Name & Description & Worst case runtime \\
    \hline
    \texttt{create()} & Creates a new linked list & $O(1)$ \\
    \hline
    \texttt{insert(x, i)} & Inserts \texttt{x} after node \texttt{i} & $O(1)$ \\
    \hline
    \texttt{delete(i)} & Removes node \texttt{i} & $O(1)$ \\
    \hline
    \texttt{lookup(i)} & Returns node \texttt{i} & $O(1)$ \\
    \hline
  \end{tabular}
\end{center}

\subsection{Arrays}

An array is a list of variables of fixed length. 
It supports three operations:

\begin{center}
  \begin{tabular}{ || c | p{6.5cm} | c || }
    \hline
    Name & Description & Worst case runtime \\
    \hline
    \texttt{create(n)} & Creates a new array of size \texttt{n} & $O(1)$ \\
    \hline
    \texttt{update(x, i)} & Overwrites the data at position \texttt{i} with \texttt{x} & $O(1)$ \\
    \hline
    \texttt{lookup(i)} & Returns the value at \texttt{i} & $O(1)$ \\
    \hline
  \end{tabular}
\end{center}

\subsection{Hash Tables}

A hash table is an array of linked lists storing key-value pairs. 
We use a \textbf{hash function} to map data to a linked list. As we 
are using linked lists, if multiple keys map to the same index, 
we can just add them to the list - and when looking up data, we 
can find the right list with the hash function and then match our key.
\\[\baselineskip]
It supports four operations:

\begin{center}
  \begin{tabular}{ || c | p{7.5cm} | c || }
    \hline
    Name & Description & Average runtime \\
    \hline
    \texttt{create(n)} & Creates a \texttt{n} sized array
    of linked lists and chooses a hash function \texttt{h} & $O(1)$ \\
    \hline
    \texttt{insert(k, v)} & Inserts the pair (\texttt{k, v}),
    if $\frac{\texttt{n}}{2}$ pairs are stored, we create a hash
    table of double the size and copy the contents into it & $O(1)$ \\
    \hline
    \texttt{delete(k)} & Deletes the pair corresponding to the key \texttt{k} & $O(1)$ \\
    \hline
    \texttt{lookup(k)} & Returns the pair corresponding to the key \texttt{k} & $O(1)$ \\
    \hline
  \end{tabular}
\end{center}

\subsubsection{Markov's Inequality}

For $X \geq 0$ a random variable with mean $\mu$, for all
$t$ in $\mathbb{R}_{\geq 0}$: \begin{gather*}
  \mathbb{P}(X \geq t) \leq \frac{\mu}{t}.
\end{gather*} So, if $X$ is the expected time it takes for an 
algorithm to terminate, we can say how likely it is for an algorithm
to terminate based on our prediction.

\section{Fast Fourier Transforms}

\subsection{Polynomials}

\subsubsection{Definition of a Polynomial}

A polynomial of degree $n$ in $\mathbb{Z}_{\geq 0}$ is a function $A$: 
\begin{gather*}
  A(x) = \sum_{i = 0}^n a_ix^i,
\end{gather*} where $a_i$ are the coefficients of $A$. We say for 
$k > n$, $k$ is a degree-bound of $A$. We can represent this by listing
the coefficients, called the \textbf{coefficient representation}.

\subsubsection{Fast Polynomial Evaluation}

We can evaluate polynomials quickly using \textit{Horner's Rule},
for a polynomial $A$ degree $n$: \begin{gather*}
  A(x) = a_0 + x(a_1 + x(a_2 + \cdots + x(a_n)))).
\end{gather*} This can be simplified in the following code:
\begin{verbatim}
int polynomial(int[] coeffs, int x) {
  int output = 0;
  for (i = n; i >= 0; i--) {
    output = (output * x) + coeffs[i]
  }
  return output;
}
\end{verbatim} We have that this is $O(n)$.

\subsubsection{Point Intersection with Polynomials}

For a given set of points of size $n$, we have that there exists a 
unique polynomial with degree-bound $n$ such that the polynomial
intersects all the given points.

\subsubsection{Point-Value Representation}

We can represent a polynomial by a set of points it intersects like so:
\begin{gather*}
  \{(x_0, y_0), \ldots, (x_n, y_n)\},
\end{gather*} for a polynomial degree $n + 1$.

\subsubsection{Polynomial Addition}

For two polynomials $A, B$ with coefficients $a_i, b_i$ and degrees $n, m$ 
respectively, we have that: \begin{gather*}
  (A + B)(x) =  \sum_{i = 0}^{\text{max}(n, m)}(a_i + b_i)x^i.
\end{gather*} If $m > n$ or vice versa, we pad out the shorter
polynomial with zeroes. We can do this with the point-value representation
by adding the '$y$-values'. We have that addition as it's defined here
is $O(n)$.

\subsubsection{Polynomial Multiplication}

For two polynomials $A, B$ with coefficients $a_i, b_i$ and degrees $n, m$ 
respectively, we have that: \begin{gather*}
  C(x) = (A \cdot B)(x) = \sum_{i = 0}^{k} c_ix_i,
\end{gather*} where $k = 2 \cdot \text{max}(n, m)$ and: \begin{gather*}
  c_i = \sum_{j = 0}^ia_jb_{j - 1}.
\end{gather*} We can do this with the point-value representation,
for: \begin{gather*}
  A = \{(x_0, y_0), \ldots, (x_n, y_n)\}, \\
  B = \{(x_{n + 1}, z_0), \ldots, (x_{n + m}, z_m)\},
\end{gather*} We have that: \begin{gather*}
  C = A \cdot B = \{(x_0, y_0 \cdot z_0), \ldots, (x_k, y_k \cdot z_k)\}
\end{gather*} This is much easier, yielding
an $O(n)$ algorithm rather than an $O(n^2)$ algorithm.

\subsection{Fast Fourier Transform}

\subsubsection{Roots of Unity}

The idea is that we evaluate a polynomial to perform pointwise
multiplication and then interpolate back into a polynomial.
We need to evaluate a polynomial of degree $n$ at $n + 1$ points to
convert it to point-value form. We use the $n + 1$ roots of unity:
\begin{gather*}
  \omega_{n+1}^k = e^{\frac{2\pi i}{n + 1}k},
\end{gather*} for $k$ in $\{0, 1, \ldots n\}$. Therefore considering:
\begin{gather*}
  y_k = A(\omega_{n + 1}^k),
\end{gather*} for $A$ a polynomial, $k$ as above, and the vector of 
all ordered $y_k$ being the \textbf{Discrete Fourier Transform (DFT)} 
of the coefficient vector of $A$.

\paragraph{Cancellation Lemma:} we have that 
$\omega_{dn}^{dk} = \omega_{n}^{k}$.

\paragraph{Halving Lemma:} we have that if $n$ is even, the set of all
the squared roots of unity is just the set of roots of unity for $\frac{n}{2}$.
\\[\baselineskip]
\textit{This is true due to the Cancellation Lemma, we have:} \begin{gather*}
  (\omega_{2k}^j)^2 = \omega_{2k}^{2j} = \omega_{k}^j.
\end{gather*}

\subsubsection{Method of the Fast Fourier Transform}

For a polynomial $A$ degree $n$, 
we define $A^{[0]}$ and $A^{[1]}$ as: \begin{align*}
  A^{[0]} &= a_0 + a_2x + \cdots + a_{n - 2}x^{(n / 2) - 1} \\
  A^{[1]} &= a_1 + a_3x + \cdots + a_{n - 1}x^{(n / 2) - 1},
\end{align*} so we have that: \begin{gather*}
  A(x) = A^{[0]}(x^2) + xA^{[1]}(x^2).
\end{gather*} So, we can split a DFT computation into two
equally sized parts, compute them, and then combine them in linear time.

\subsection{Polynomial Multiplication}

So, the steps are laid out, for polynomials $A, B$ with degree bound 
$n$, as follows: \begin{itemize}
  \item Set the degree of $A$ and $B$ to $2n$, padding with zeroes
  \item Perform the fast Fourier transform
  \item Form our point-value representation and multiply pointwise
  \item Interpolate with the inverse fast Fourier transform.
\end{itemize} This process is $O(n \log(n))$.

\end{document}