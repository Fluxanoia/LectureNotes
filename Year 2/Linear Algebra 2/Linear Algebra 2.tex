\documentclass[a4paper, 12pt, twoside]{article}
\usepackage[left = 3cm, right = 3cm]{geometry}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{multicol}

\begin{document}

\title{Linear Algebra 2 Notes}
\date{}
\author{\textit{paraphrased by} Tyler Wright}
\maketitle

\vfill

\textit{An important note, these notes are absolutely \textbf{NOT}
  guaranteed to be correct, representative of the course, or rigorous.
  Any result of this is not the author's fault.}

\newpage

\section{Groups, Rings, and Fields}

\subsection{Definition of a Group}

A group is a set $G$ combined with a group operation 
$\circ : G \times G \to G$ such that: \begin{itemize}
  \item For all $g, h, j$ in $G$, $g(hj) = (gh)j$ (associativity)
  \item There exists $e$ in $G$ such that $eg = ge = g$ for all
  $g$ in $G$
  \item For all $g$ in $G$, there exists $g^{-1}$ in $G$ such that
  $gg^{-1} = g^{-1}g = e$ where $e$ is the identity of $G$.
\end{itemize}

\subsection{Definition of a Homomorphism}

A homomorphism between two groups $G, H$ is a function $f : G \to H$
such that $f(gh) = f(g)f(h)$ for all $g, h$ in $G$.

\subsection{Properties of Homomorphisms}

We can derive some properties of homomorphisms, for
$G, H$ groups, and $f : G \to H$ a homomorphism: \begin{itemize}
  \item The image of the identity in $G$ is the identity in $H$
  \item The kernel of $f$ is a subgroup of $G$
  \item The image of $f$ is a subgroup of $H$
  \item Bijective homomorphisms are isomorphisms.
\end{itemize}

\subsection{Definition of a Ring}

A ring with unity is a set $R$ along with an addition map $+$, and
a multiplication map $\circ$ where $+, \circ : R \times R \to R$
such that: \begin{itemize}
  \item $(R, +)$ is an abelian group (of which the identity is called zero)
  \item The multiplication operation is associative
  \item The multiplication operation has a two-sided identity not equal
  to the zero identity (called one)
  \item For all $a, b, c$ in $R$, $a(b+c) = ab + ac$ and $(a+b)c = ac + bc$.
\end{itemize} A ring is commutative if the multiplication operation is commutative.

\subsection{Definition of a Subring}

For the ring $R = (R', +, \circ)$ and $S$ a set, $S$ is a subring
of $R$ if $S \subseteq R'$ and $(S, +, \circ)$ is a ring.

\subsection{Definition of a Ring Homomorphism}

For rings with unity $R$ and $S$, $f : R \to S$ is a ring homomorphism if for all
$a, b$ in $R$: \begin{align*}
  f(a + b) &= f(a) + f(b) \\
  f(ab) &= f(a)f(b) \\
  f(1_R) &= 1_S
\end{align*} \textit{Essentially, this says that $f$ is a homomorphism for the
groups formed by $R$ and $S$ under addition and multiplication.}

\subsection{Definition of a Field}

A field $\mathbb{F}$ is a ring with unity with the following properties: \begin{itemize}
  \item $(\mathbb{F}\setminus\{0\}, \circ)$ is an abelian group.
\end{itemize}

\subsection{Definition of the Field Characteristic}

For a field $\mathbb{F}$, the field characteristic  char($\mathbb{F}$) is the 
smallest positive integer $n$ such that: \begin{gather*}
  \sum_{i = 1}^{n} 1 = 1 + 1 + \ldots + 1 = 0,
\end{gather*} or zero if no such value $n$ exists.

\subsection{Definition of the Algebraic Closure of Fields}

A field $\mathbb{F}$ is called algebraically closed if all non-constant polynomials 
with coefficients in $\mathbb{F}$ also has a root in $\mathbb{F}$.

\section{Vector Spaces}

\subsection{Definition of a Vector Space}

A vector space over a field $\mathbb{F}$ is a set $V$ with an addition
operation $+ : V \times V \to V$ and a scalar multiplication operations
$\circ : \mathbb{F} \times V \to V$ such that for all $a, b$ in $\mathbb{F}$
and $v, w$ in $V$: \begin{itemize}
  \item $(V, +)$ is an abelian group
  \item $1 \circ v = v$ where $1$ is the multiplicative identity of $\mathbb{F}$
  \item $(ab) \circ v = a \circ (b \circ v)$
  \item $(a + b) \circ v = a \circ v + b \circ v$
  \item $a \circ (v + w) = a \circ v + a \circ w$.
\end{itemize}

\subsection{Definition of a Subspace}

For $V$ a vector space over the field $\mathbb{F}$ and $W$ a set, $W$ is a 
subspace of $V$ if it is a subset of $V$ and is a vector space with respect 
to the addition and scalar multiplication defined by $V$.
\\[\baselineskip]
It is sufficient to verify that for any $a$ in $\mathbb{F}$ and $v, w$ in $W$ we
have that $a(v + w)$ is in $W$.

\subsection{Definition of a Linear Combination}

For a set $V$ with addition operation $+$, a field $\mathbb{F}$ and $n$ in 
$\mathbb{N}$, a linear combination of $v_1, \ldots, v_n$ in $V$ is: \begin{gather*}
  \sum_{i = 1}^n a_iv_i,
\end{gather*} for $a_1, \ldots, a_n$ in $\mathbb{F}$.

\subsection{Definition of the Span}

For a set $V$ with addition operation $+$ and a field $\mathbb{F}$, the span 
of $W \subseteq V$ is the set of all the linear combinations of the values
in $W$. Denoted by span($W$).

\subsection{Definition of Linear Independence}

For a vector space $V$ and $W \subseteq V$, we say $W$ is linearly dependent if
there exists a non-trivial linear combination of all the vectors in $W$ 
equal to zero (and linearly independent otherwise).

\subsection{Properties of Linear Independence}

For a vector space $V$ with $W \subseteq V$: \begin{itemize}
  \item $0 \in W \Rightarrow W$ is linearly independent
  \item $W$ linearly independent $\Rightarrow$ any $X \subseteq W$ 
  is linearly independent
  \item If there's a linearly dependent subset of $W$, then $W$
  is linearly dependent.
\end{itemize}

\subsection{Definition of a Basis}

For a vector space $V$ with $W \subseteq V$, if $W$ is linearly independent
and span($W$) = $V$, we say that $W$ is a basis of $V$.
\\[\baselineskip]
Saying $W$ is a basis is equivalent to saying that each vector in $V$ can
be \textbf{uniquely} written as a linear combination of vectors in $W$.
\\[\baselineskip]
Additionally, for finite vector spaces, we have that all bases have the same
amount of elements.

\subsection{Definition of Dimension}

For non-infinite bases, we say that the value of the basis is the dimension
of the vector space it is a member of. Vector spaces with such bases are called
finite-dimensional and all other vector spaces are infinite-dimensional.
\\[\baselineskip]
By convention, for a vector space $V$, dim($\{0_V\}$) $= 0$.

\newpage

\subsection{Isomorphisms from Dimension}

For $V, W$ finite-dimensional vector spaces over $\mathbb{F}$
with dim$(V)$ = dim$(W)$, then $V \cong W$.
\\[\baselineskip]
If we set $n = \text{dim}(V)$, we have that $V \cong \mathbb{F}^{n}$.
\\[\baselineskip]
\textit{Such an isomorphism can be found by mapping a vector in
terms of some chosen basis vectors 
($v = a_1v_1 + a_2v_2 + \cdots + a_nv_n$) to the coefficients
$(a_1, a_2, \ldots, a_n)$.}

\section{Linear Maps}

\subsection{Definition of a Linear Map}

Let $V, W$ be vector spaces over a field $\mathbb{F}$, we have that
$f:V \to W$ is a linear map if for all $a, b$ in $\mathbb{F}$ and
$u, v$ in $V$: \begin{gather*}
  f(au+bv) = af(u) + bf(v).
\end{gather*} A bijective linear map is called an isomorphism.
If $f: V \to W$ is an isomorphism, we say that $V$ and $W$ are 
isomorphic, denoted by $V \cong W$. 

\subsection{The Kernel of Linear Maps}

Let $V, W$ be vector spaces over a field $\mathbb{F}$, and
$f : V \to W$ be a linear map. We define the kernel of $f$ as: \begin{gather*}
  \text{Ker}(f) = \{v \in V : f(v) = 0_{\mathbb{F}}\}.
\end{gather*} Saying Ker($f)$ is $\{0_\mathbb{F}\}$ is equivalent
to saying $f$ is injective.

\subsection{The Image of Linear Maps}

Let $V, W$ be vector spaces over a field $\mathbb{F}$, and
$f : V \to W$ be a linear map. We define the image of $f$ as: \begin{gather*}
  \text{Im}(f) = \{w \in W : \exists \, v \in V \text{ with } f(v) = w\}.
\end{gather*} Saying Im($f)$ is $W$ is equivalent
to saying $f$ is surjective.

\subsection{The Inverse of Linear Maps}

For a bijective linear map $f$, the inverse of $f$ is also linear.

\subsection{Properties of the Set of Linear Maps}

For $V, W$ vector spaces over a field $\mathbb{F}$, we define
$\mathcal{L}(V, W)$ to be the set of all linear maps from $V$
to $W$.

\subsection{The Rank-Nullity Theorem}

For $V, W$ finite-dimensional vector spaces and 
$f : V \to W$ a linear map, we have that: \begin{gather*}
  \text{dim}(V) = \text{dim(Ker(}f)) + \text{dim(Im(}f)).
\end{gather*} Thus, for a linear map $f : V \to V$, if $f$ is
injective or surjective then it's an isomorphism.

\end{document}